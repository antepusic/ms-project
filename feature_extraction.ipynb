{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "CLEAN_DATA_DIR = \"cleaned_data\"\n",
    "FINAL_DATA_DIR = \"data\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Data shapes:\n",
      "Labels (838, 21)\n",
      "Temperature (838, 30)\n",
      "Heartrate (838, 30)\n",
      "GSR (838, 30)\n",
      "RR (838, 30)\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv(f\"{CLEAN_DATA_DIR}/segments_labels.csv\", index_col=0)\n",
    "temp_df = pd.read_csv(f\"{CLEAN_DATA_DIR}/segments_temperature.csv\", index_col=0)\n",
    "hr_df = pd.read_csv(f\"{CLEAN_DATA_DIR}/segments_heartrate.csv\", index_col=0)\n",
    "gsr_df = pd.read_csv(f\"{CLEAN_DATA_DIR}/segments_gsr.csv\", index_col=0)\n",
    "rr_df = pd.read_csv(f\"{CLEAN_DATA_DIR}/segments_rr.csv\", index_col=0)\n",
    "\n",
    "# TODO remove the following\n",
    "print(\"Done\")\n",
    "\n",
    "# check 30-second segments\n",
    "print(\"Data shapes:\")\n",
    "print(\"Labels\", label_df.shape)\n",
    "print(\"Temperature\", temp_df.shape)\n",
    "print(\"Heartrate\", hr_df.shape)\n",
    "print(\"GSR\", gsr_df.shape)\n",
    "print(\"RR\", rr_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def extract_stat_features(df, domain=\"\"):\n",
    "    stat_features_names = [\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "        \"skew\",\n",
    "        \"kurtosis\",\n",
    "        \"diff\",\n",
    "        \"diff2\",\n",
    "        \"q25\",\n",
    "        \"q75\",\n",
    "        \"qdev\",\n",
    "        \"max-min\",\n",
    "    ]\n",
    "\n",
    "    final_names = [f\"{domain}_{x}\" for x in stat_features_names]\n",
    "    values = np.column_stack(\n",
    "        [\n",
    "            df.mean(axis=1).values,  # mean\n",
    "            df.std(axis=1).values,  # standard deviation\n",
    "            df.skew(axis=1).values,  # skewness\n",
    "            df.kurtosis(axis=1).values,  # kurtosis\n",
    "            df.diff(axis=1).mean(axis=1).values,  # 1st derivative mean\n",
    "            df.diff(axis=1).diff(axis=1).mean(axis=1).values,  # 2nd derivative mean\n",
    "            df.quantile(0.25, axis=1).values,  # 25th quantile\n",
    "            df.quantile(0.75, axis=1).values,  # 75th quantile\n",
    "            df.quantile(0.75, axis=1).values - df.quantile(0.25, axis=1).values,\n",
    "            df.max(axis=1).values - df.min(axis=1).values,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(values, columns=final_names)\n",
    "\n",
    "\n",
    "def extract_eda_features(df):\n",
    "    feature_keys = [\n",
    "        \"SCR_Onsets\",\n",
    "        \"SCR_Peaks\",\n",
    "        \"SCR_Height\",\n",
    "        \"SCR_Amplitude\",\n",
    "        \"SCR_RiseTime\",\n",
    "        \"SCR_Recovery\",\n",
    "        \"SCR_RecoveryTime\",\n",
    "    ]\n",
    "\n",
    "    # for each feature key we will calculate min, max and mean values\n",
    "    feature_names = []\n",
    "    for f in feature_keys:\n",
    "        feature_names.append(f\"min_{f}\")\n",
    "        feature_names.append(f\"max_{f}\")\n",
    "        feature_names.append(f\"mean_{f}\")\n",
    "\n",
    "    # iterate through all 30-second segments\n",
    "    features_arr = []\n",
    "    for i in range(len(df)):\n",
    "        my_eda = df.iloc[i].dropna()\n",
    "        my_eda_resampled = resample(\n",
    "            my_eda.values, len(my_eda.values) * 10\n",
    "        )  # upsampling (neurokit requires 10Hz sampling frequency)\n",
    "        signals, info = nk.eda_process(my_eda_resampled, sampling_rate=10)\n",
    "\n",
    "        segment_features = []\n",
    "        for k in feature_keys:\n",
    "            feature_min = 0\n",
    "            feature_max = 0\n",
    "            feature_mean = 0\n",
    "\n",
    "            values = info[k]\n",
    "            values = values[~np.isnan(values)]\n",
    "            if (\n",
    "                len(values) > 0\n",
    "            ):  # update feature-values if there is at least 1 detected value (e.g., at least one peak), else leave 0\n",
    "                feature_min = np.min(values)\n",
    "                feature_max = np.max(values)\n",
    "                feature_mean = np.mean(values)\n",
    "            segment_features.extend([feature_min, feature_max, feature_mean])\n",
    "        features_arr.append(segment_features)\n",
    "\n",
    "    return pd.DataFrame(features_arr, columns=feature_names)\n",
    "\n",
    "\n",
    "def extract_hrv_features(df):\n",
    "    feature_names = [\n",
    "        \"HRV_RMSSD\",\n",
    "        \"HRV_MeanNN\",\n",
    "        \"HRV_SDNN\",\n",
    "        \"HRV_SDSD\",\n",
    "        \"HRV_CVNN\",\n",
    "        \"HRV_CVSD\",\n",
    "        \"HRV_MedianNN\",\n",
    "        \"HRV_MadNN\",\n",
    "        \"HRV_MCVNN\",\n",
    "        \"HRV_IQRNN\",\n",
    "        \"HRV_pNN50\",\n",
    "        \"HRV_pNN20\",\n",
    "        \"HRV_TINN\",\n",
    "        \"HRV_HTI\",\n",
    "        \"HRV_ULF\",\n",
    "        \"HRV_VLF\",\n",
    "        \"HRV_LF\",\n",
    "        \"HRV_HF\",\n",
    "        \"HRV_VHF\",\n",
    "        \"HRV_LFHF\",\n",
    "        \"HRV_LFn\",\n",
    "        \"HRV_HFn\",\n",
    "        \"HRV_LnHF\",\n",
    "        \"HRV_SD1\",\n",
    "        \"HRV_SD2\",\n",
    "        \"HRV_SD1SD2\",\n",
    "        \"HRV_S\",\n",
    "        \"HRV_CSI\",\n",
    "        \"HRV_CVI\",\n",
    "        \"HRV_CSI_Modified\",\n",
    "        \"HRV_PIP\",\n",
    "        \"HRV_IALS\",\n",
    "        \"HRV_PSS\",\n",
    "        \"HRV_PAS\",\n",
    "        \"HRV_GI\",\n",
    "        \"HRV_SI\",\n",
    "        \"HRV_AI\",\n",
    "        \"HRV_PI\",\n",
    "        \"HRV_C1d\",\n",
    "        \"HRV_C1a\",\n",
    "        \"HRV_SD1d\",\n",
    "        \"HRV_SD1a\",\n",
    "        \"HRV_C2d\",\n",
    "        \"HRV_C2a\",\n",
    "        \"HRV_SD2d\",\n",
    "        \"HRV_SD2a\",\n",
    "        \"HRV_Cd\",\n",
    "        \"HRV_Ca\",\n",
    "        \"HRV_SDNNd\",\n",
    "        \"HRV_SDNNa\",\n",
    "        \"HRV_ApEn\",\n",
    "        \"HRV_SampEn\",\n",
    "        \"HRV_MSE\",\n",
    "        \"HRV_CMSE\",\n",
    "        \"HRV_RCMSE\",\n",
    "        \"HRV_DFA\",\n",
    "        \"HRV_CorrDim\",\n",
    "    ]\n",
    "\n",
    "    features_arr = []\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            rr = df.iloc[i].dropna()  # 30-second rr intervals\n",
    "\n",
    "            # convert rr intervals to peaks array (input expected by neurokit)\n",
    "            peaks_rr = np.zeros((len(rr) + 1) * 1000)\n",
    "            peaks_rr[0] = 1\n",
    "            prev_peak = 0\n",
    "            for r in rr:\n",
    "                peak_idx = prev_peak + int(r * 1000)\n",
    "                prev_peak = peak_idx\n",
    "                peaks_rr[peak_idx] = 1\n",
    "\n",
    "            segment_features = nk.hrv(peaks_rr, sampling_rate=1000, show=False)\n",
    "            features_arr.append(segment_features)\n",
    "        except Exception:\n",
    "            values = np.zeros(len(feature_names))\n",
    "            segment_features = pd.DataFrame([values], columns=feature_names)\n",
    "            features_arr.append(segment_features)\n",
    "\n",
    "    return pd.concat(features_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'print(\\n    \"Statistical features\",\\n    stat_feat_all.shape,\\n)\\nprint(\"GSR expert features\", gsr_expert_features.shape)\\nprint(\"HRV features\", hrv_features.shape)\\nprint(\"Merged features\", all_features.shape)\\nprint(\"Nan values\", all_features.isnull().sum().sum())\\n\\nprint(all_features.shape, label_df.shape)'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_features() -> pd.DataFrame:  # ≈ 30 s\n",
    "    temp_df_rolling_mean: pd.DataFrame = temp_df.rolling(3, axis=1).mean()\n",
    "    hr_df_rolling_mean: pd.DataFrame = hr_df.rolling(3, axis=1).mean()\n",
    "    gsr_df_rolling_mean: pd.DataFrame = gsr_df.rolling(3, axis=1).mean()\n",
    "    rr_df_rolling_mean: pd.DataFrame = rr_df.rolling(3, axis=1).mean()\n",
    "\n",
    "    temp_stat_features: pd.DataFrame = extract_stat_features(\n",
    "        temp_df_rolling_mean, \"temp\"\n",
    "    )\n",
    "    hr_stat_features: pd.DataFrame = extract_stat_features(hr_df_rolling_mean, \"hr\")\n",
    "    gsr_stat_features: pd.DataFrame = extract_stat_features(gsr_df_rolling_mean, \"gsr\")\n",
    "    rr_stat_features: pd.DataFrame = extract_stat_features(rr_df_rolling_mean, \"rr\")\n",
    "\n",
    "    stat_feat_all: pd.DataFrame = pd.concat(\n",
    "        [temp_stat_features, hr_stat_features, gsr_stat_features, rr_stat_features],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    gsr_expert_features = extract_eda_features(gsr_df_rolling_mean)\n",
    "\n",
    "    hrv_features: pd.DataFrame = extract_hrv_features(rr_df_rolling_mean)\n",
    "    hrv_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    good_features = hrv_features.isnull().sum() == 0\n",
    "    hrv_features = hrv_features[hrv_features.columns[good_features]]\n",
    "    hrv_features = hrv_features.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "    all_features: pd.DataFrame = pd.concat(\n",
    "        [stat_feat_all, gsr_expert_features, hrv_features], axis=1\n",
    "    )\n",
    "\n",
    "    return all_features\n",
    "\n",
    "\n",
    "\"\"\"print(\n",
    "    \"Statistical features\",\n",
    "    stat_feat_all.shape,\n",
    ")\n",
    "print(\"GSR expert features\", gsr_expert_features.shape)\n",
    "print(\"HRV features\", hrv_features.shape)\n",
    "print(\"Merged features\", all_features.shape)\n",
    "print(\"Nan values\", all_features.isnull().sum().sum())\n",
    "\n",
    "print(all_features.shape, label_df.shape)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "feature_df: pd.DataFrame = compute_features()\n",
    "\n",
    "feature_df.to_csv(f\"{FINAL_DATA_DIR}/features.csv\")\n",
    "label_df.to_csv(f\"{FINAL_DATA_DIR}/labels.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def normalize_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    # session-specific min-max normalization\n",
    "    # assuming there’s one session per user\n",
    "    pass\n",
    "\n",
    "def standardize_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    # session-specific standardization\n",
    "    # assuming there’s one session per user\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
