{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"CogLoad-1Hz\"\n",
    "CLEAN_DATA_PATH = \"cleaned_data\"\n",
    "\n",
    "NOT_EXPERIMENT = {\"quest\", \"post\"}\n",
    "\n",
    "WINDOW_SIZE = 30  # seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def get_tasks(files_path: str) -> Set[str]:\n",
    "    tasks = set()\n",
    "\n",
    "    for file in os.listdir(files_path):\n",
    "        if \"sensors\" not in file:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(f\"{files_path}/{file}\")\n",
    "        tasks |= set(df[\"task\"].unique().flatten())\n",
    "\n",
    "    return tasks - NOT_EXPERIMENT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def get_segments(files_path: str) -> [np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    tasks: Set[str] = get_tasks(files_path=files_path)\n",
    "\n",
    "    _label_segments = []\n",
    "    _temp_segments = []\n",
    "    _hr_segments = []\n",
    "    _gsr_segments = []\n",
    "    _rr_segments = []\n",
    "    segment_sensor_data: pd.DataFrame = pd.DataFrame()\n",
    "    for file in os.listdir(files_path):\n",
    "        if \"sensor\" not in file:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(f\"{files_path}/{file}\")\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.dropna()\n",
    "\n",
    "        for task in tasks:\n",
    "            for level in df[df.task == task].level.unique():\n",
    "                task_df = df[(df.task == task) & (df.level == level)]\n",
    "                if len(task_df) == 0:\n",
    "                    continue\n",
    "\n",
    "                if \"rest\" in task and task not in (\"n2_rest\", \"n3_rest\"):\n",
    "                    timestamp_end_arr = []\n",
    "                    timestamp_end_arr.extend(\n",
    "                        task_df[task_df.timestamp.diff() > 10000].timestamp.values\n",
    "                    )\n",
    "                    timestamp_end_arr.append(task_df.timestamp.iloc[-1])\n",
    "\n",
    "                    for segment_end in timestamp_end_arr:\n",
    "                        segment_sensor_data = task_df[task_df.timestamp < segment_end]\n",
    "                        segment_sensor_data = segment_sensor_data.iloc[-WINDOW_SIZE:]\n",
    "\n",
    "                        if segment_sensor_data.shape[0] != WINDOW_SIZE:\n",
    "                            continue\n",
    "\n",
    "                        _label_segments.append(segment_sensor_data.iloc[-1].values)\n",
    "\n",
    "                        _temp_segments.append(\n",
    "                            segment_sensor_data.temperature.values[:WINDOW_SIZE]\n",
    "                        )\n",
    "                        _hr_segments.append(segment_sensor_data.hr.values[:WINDOW_SIZE])\n",
    "                        _gsr_segments.append(\n",
    "                            segment_sensor_data.gsr.values[:WINDOW_SIZE]\n",
    "                        )\n",
    "                        _rr_segments.append(segment_sensor_data.rr.values[:WINDOW_SIZE])\n",
    "                else:\n",
    "                    segment_end = task_df.timestamp.iloc[-1]\n",
    "                    segment_start = segment_end - WINDOW_SIZE * 1000\n",
    "                    segment_sensor_data = task_df[\n",
    "                        (task_df.timestamp <= segment_end)\n",
    "                        & (task_df.timestamp >= segment_start)\n",
    "                    ]\n",
    "                    if 25 < segment_sensor_data.shape[0] < WINDOW_SIZE:\n",
    "                        segment_sensor_data = df[\n",
    "                            (df.timestamp <= segment_end)\n",
    "                            & (df.timestamp >= segment_start)\n",
    "                        ]\n",
    "\n",
    "                    if len(segment_sensor_data) < WINDOW_SIZE:\n",
    "                        continue\n",
    "\n",
    "                    _label_segments.append(segment_sensor_data.iloc[-1].values)\n",
    "\n",
    "                    _temp_segments.append(\n",
    "                        segment_sensor_data.temperature.values[:WINDOW_SIZE]\n",
    "                    )\n",
    "                    _hr_segments.append(segment_sensor_data.hr.values[:WINDOW_SIZE])\n",
    "                    _gsr_segments.append(segment_sensor_data.gsr.values[:WINDOW_SIZE])\n",
    "                    _rr_segments.append(segment_sensor_data.rr.values[:WINDOW_SIZE])\n",
    "\n",
    "    _label_segments = np.stack(_label_segments)\n",
    "    _temp_segments = np.stack(_temp_segments)\n",
    "    _hr_segments = np.stack(_hr_segments)\n",
    "    _gsr_segments = np.stack(_gsr_segments)\n",
    "    _rr_segments = np.stack(_rr_segments)\n",
    "    _column_names = segment_sensor_data.columns.values\n",
    "\n",
    "    print(\n",
    "        type(_label_segments),\n",
    "        type(_temp_segments),\n",
    "        type(_hr_segments),\n",
    "        type(_gsr_segments),\n",
    "        type(_rr_segments),\n",
    "        type(_column_names),\n",
    "    )\n",
    "    return (\n",
    "        _label_segments,\n",
    "        _temp_segments,\n",
    "        _hr_segments,\n",
    "        _gsr_segments,\n",
    "        _rr_segments,\n",
    "        _column_names,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    label_segments,\n",
    "    temp_segments,\n",
    "    hr_segments,\n",
    "    gsr_segments,\n",
    "    rr_segments,\n",
    "    column_names,\n",
    ") = get_segments(files_path=RAW_DATA_PATH)\n",
    "\n",
    "label_df = pd.DataFrame(label_segments, columns=column_names)\n",
    "\n",
    "temp_df = pd.DataFrame(temp_segments)\n",
    "hr_df = pd.DataFrame(hr_segments)\n",
    "gsr_df = pd.DataFrame(gsr_segments)\n",
    "rr_df = pd.DataFrame(rr_segments)\n",
    "\n",
    "label_df.to_csv(f\"{CLEAN_DATA_PATH}/segment_labels.csv\")\n",
    "temp_df.to_csv(f\"{CLEAN_DATA_PATH}/segment_temperature.csv\")\n",
    "hr_df.to_csv(f\"{CLEAN_DATA_PATH}/segment_heartrate.csv\")\n",
    "gsr_df.to_csv(f\"{CLEAN_DATA_PATH}/segment_gsr.csv\")\n",
    "rr_df.to_csv(f\"{CLEAN_DATA_PATH}/segment_rr.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def csv_equal(comparee_path: str, standard_path: str) -> bool:\n",
    "    if standard_path == comparee_path:\n",
    "        return True\n",
    "\n",
    "    comparee_df: pd.DataFrame = pd.read_csv(comparee_path)\n",
    "    standard_df: pd.DataFrame = pd.read_csv(standard_path)\n",
    "\n",
    "    if len(comparee_df) != len(standard_df):\n",
    "        return False\n",
    "\n",
    "    merged_df: pd.DataFrame = pd.merge(\n",
    "        comparee_df.drop(\"Unnamed: 0\", axis=1),\n",
    "        standard_df.drop(\"Unnamed: 0\", axis=1),\n",
    "        how=\"outer\",\n",
    "        left_index=False,\n",
    "        right_index=False,\n",
    "        indicator=True,\n",
    "    )\n",
    "    sources: pd.Index = (\n",
    "        merged_df[\"_merge\"].unique().remove_unused_categories().categories\n",
    "    )\n",
    "    if len(sources) > 1 or \"both\" not in sources:\n",
    "        return False\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def csvs_equal(comparee_csv_dir: str, standard_csv_dir: str) -> bool:\n",
    "    comparee_files: List[str] = os.listdir(comparee_csv_dir)\n",
    "    standard_files: List[str] = os.listdir(standard_csv_dir)\n",
    "\n",
    "    comparee_files.sort()\n",
    "    standard_files.sort()\n",
    "\n",
    "    if comparee_files != standard_files:\n",
    "        return False\n",
    "\n",
    "    for comparee_file, standard_file in zip(comparee_files, standard_files):\n",
    "        files_equal: bool = csv_equal(\n",
    "            comparee_path=f\"{comparee_csv_dir}/{comparee_file}\",\n",
    "            standard_path=f\"{standard_csv_dir}/{standard_file}\",\n",
    "        )\n",
    "        if not files_equal:\n",
    "            return False\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs_equal(\"cleaned_data\", \"initial_data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
