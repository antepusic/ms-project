{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"CogLoad-1Hz\"\n",
    "CLEAN_DATA_DIR = \"clean_data\"\n",
    "\n",
    "NOT_EXPERIMENT = {\"quest\", \"post\"}\n",
    "\n",
    "WINDOW_SIZE = 30  # seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def get_tasks(files_path: str) -> Set[str]:\n",
    "    tasks: Set[str] = set()\n",
    "\n",
    "    for file in os.listdir(files_path):\n",
    "        if \"sensors\" not in file:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(f\"{files_path}/{file}\")\n",
    "        tasks |= set(df[\"task\"].unique().flatten())\n",
    "\n",
    "    return tasks - NOT_EXPERIMENT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Segment observations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def segment(path: str, tasks: Set[str]) -> [pd.DataFrame, pd.DataFrame]:\n",
    "    if \"sensors\" not in path:\n",
    "        raise Exception(\"File doesnâ€™t contain sensor data\")\n",
    "\n",
    "    df: pd.DataFrame = pd.read_csv(path)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna()\n",
    "\n",
    "    label_segments = []\n",
    "    temp_segments = []\n",
    "    hr_segments = []\n",
    "    gsr_segments = []\n",
    "    rr_segments = []\n",
    "    segment_sensor_data: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "    for task in tasks:\n",
    "        for level in df[df.task == task].level.unique():\n",
    "            task_df = df[(df.task == task) & (df.level == level)]\n",
    "            if len(task_df) == 0:\n",
    "                continue\n",
    "\n",
    "            if \"rest\" in task and task not in (\"n2_rest\", \"n3_rest\"):\n",
    "                timestamp_end_arr = []\n",
    "                timestamp_end_arr.extend(\n",
    "                    task_df[task_df.timestamp.diff() > 10000].timestamp.values\n",
    "                )\n",
    "                timestamp_end_arr.append(task_df.timestamp.iloc[-1])\n",
    "\n",
    "                for segment_end in timestamp_end_arr:\n",
    "                    segment_sensor_data = task_df[task_df.timestamp < segment_end]\n",
    "                    segment_sensor_data = segment_sensor_data.iloc[-WINDOW_SIZE:]\n",
    "\n",
    "                    if segment_sensor_data.shape[0] != WINDOW_SIZE:\n",
    "                        continue\n",
    "\n",
    "                    label_segment: np.ndarray = segment_sensor_data.iloc[-1].values\n",
    "                    if any(\n",
    "                        np.array_equal(label_segment, ls_i) for ls_i in label_segments\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    label_segments.append(label_segment)\n",
    "\n",
    "                    temp_segments.append(\n",
    "                        segment_sensor_data.temperature.values[:WINDOW_SIZE]\n",
    "                    )\n",
    "                    hr_segments.append(segment_sensor_data.hr.values[:WINDOW_SIZE])\n",
    "                    gsr_segments.append(segment_sensor_data.gsr.values[:WINDOW_SIZE])\n",
    "                    rr_segments.append(segment_sensor_data.rr.values[:WINDOW_SIZE])\n",
    "            else:\n",
    "                segment_end = task_df.timestamp.iloc[-1]\n",
    "                segment_start = segment_end - WINDOW_SIZE * 1000\n",
    "                segment_sensor_data = task_df[\n",
    "                    (task_df.timestamp <= segment_end)\n",
    "                    & (task_df.timestamp >= segment_start)\n",
    "                ]\n",
    "                if 25 < segment_sensor_data.shape[0] < WINDOW_SIZE:\n",
    "                    segment_sensor_data = df[\n",
    "                        (df.timestamp <= segment_end) & (df.timestamp >= segment_start)\n",
    "                    ]\n",
    "\n",
    "                if len(segment_sensor_data) < WINDOW_SIZE:\n",
    "                    continue\n",
    "\n",
    "                label_segment: np.ndarray = segment_sensor_data.iloc[-1].values\n",
    "                if any(np.array_equal(label_segment, ls_i) for ls_i in label_segments):\n",
    "                    continue\n",
    "\n",
    "                label_segments.append(label_segment)\n",
    "\n",
    "                temp_segments.append(\n",
    "                    segment_sensor_data.temperature.values[:WINDOW_SIZE]\n",
    "                )\n",
    "                hr_segments.append(segment_sensor_data.hr.values[:WINDOW_SIZE])\n",
    "                gsr_segments.append(segment_sensor_data.gsr.values[:WINDOW_SIZE])\n",
    "                rr_segments.append(segment_sensor_data.rr.values[:WINDOW_SIZE])\n",
    "\n",
    "    label_segments = np.stack(label_segments)\n",
    "    column_names = segment_sensor_data.columns.values\n",
    "\n",
    "    temp_segments = np.stack(temp_segments)\n",
    "    hr_segments = np.stack(hr_segments)\n",
    "    gsr_segments = np.stack(gsr_segments)\n",
    "    rr_segments = np.stack(rr_segments)\n",
    "\n",
    "    _segments: pd.DataFrame = pd.DataFrame(\n",
    "        np.concatenate([temp_segments, hr_segments, gsr_segments, rr_segments], axis=1)\n",
    "    )\n",
    "    _labels: pd.DataFrame = pd.DataFrame(label_segments, columns=column_names)\n",
    "\n",
    "    return _segments, _labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def clean_data(raw_data_dir: str, save_dir: str):\n",
    "    tasks: Set[str] = get_tasks(files_path=RAW_DATA_DIR)\n",
    "\n",
    "    for file_name in sorted(os.listdir(raw_data_dir)):\n",
    "        segments, labels = segment(path=f\"{RAW_DATA_DIR}/{file_name}\", tasks=tasks)\n",
    "\n",
    "        user_id: str = file_name.split(\"_\")[0]\n",
    "        segments.to_csv(f\"{save_dir}/{user_id}_segments.csv\")\n",
    "        labels.to_csv(f\"{save_dir}/{user_id}_labels.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def data_equal(comparee_dir: str, standard_dir: str) -> bool:\n",
    "    # Check if the directory is compared with itself\n",
    "    if comparee_dir == standard_dir:\n",
    "        return True\n",
    "\n",
    "    # Check if both sources have data of the same shape\n",
    "    comparee_segments: pd.DataFrame = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(f\"{comparee_dir}/{file_name}\")\n",
    "            for file_name in os.listdir(comparee_dir)\n",
    "            if \"segments\" in file_name\n",
    "        ]\n",
    "    )\n",
    "    standard_segments: pd.DataFrame = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(f\"{standard_dir}/segment_{data_type}.csv\")\n",
    "            for data_type in [\"temperature\", \"heartrate\", \"gsr\", \"rr\"]\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    comparee_segments = comparee_segments.drop(\"Unnamed: 0\", axis=1)\n",
    "    standard_segments = standard_segments.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    comparee_labels: pd.DataFrame = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(f\"{comparee_dir}/{file_name}\")\n",
    "            for file_name in os.listdir(comparee_dir)\n",
    "            if \"labels\" in file_name\n",
    "        ]\n",
    "    )\n",
    "    standard_labels: pd.DataFrame = pd.read_csv(f\"{standard_dir}/segment_labels.csv\")\n",
    "\n",
    "    comparee_labels = comparee_labels.drop(\"Unnamed: 0\", axis=1)\n",
    "    standard_labels = standard_labels.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    if (\n",
    "        comparee_segments.shape != standard_segments.shape\n",
    "        or comparee_labels.shape != standard_labels.shape\n",
    "    ):\n",
    "        print(comparee_segments.shape, standard_segments.shape)\n",
    "        print(comparee_labels.shape, standard_labels.shape)\n",
    "        # return False\n",
    "\n",
    "    # Check if both sources contain the same rows\n",
    "    comparee_segments.columns = range(comparee_segments.shape[1])\n",
    "    standard_segments.columns = range(standard_segments.shape[1])\n",
    "\n",
    "    merged_segments: pd.DataFrame = pd.merge(\n",
    "        comparee_segments,\n",
    "        standard_segments,\n",
    "        how=\"outer\",\n",
    "        left_index=False,\n",
    "        right_index=False,\n",
    "        indicator=True,\n",
    "    )\n",
    "    merged_labels: pd.DataFrame = pd.merge(\n",
    "        comparee_labels,\n",
    "        standard_labels,\n",
    "        how=\"outer\",\n",
    "        left_index=False,\n",
    "        right_index=False,\n",
    "        indicator=True,\n",
    "    )\n",
    "\n",
    "    sources_segments: pd.Index = (\n",
    "        merged_segments[\"_merge\"].unique().remove_unused_categories().categories\n",
    "    )\n",
    "    sources_labels: pd.Index = (\n",
    "        merged_labels[\"_merge\"].unique().remove_unused_categories().categories\n",
    "    )\n",
    "\n",
    "    if len(sources_segments) > 1 or \"both\" not in sources_segments:\n",
    "        return False\n",
    "    if len(sources_labels) > 1 or \"both\" not in sources_labels:\n",
    "        return False\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 120) (838, 120)\n",
      "(837, 21) (838, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data(raw_data_dir=RAW_DATA_DIR, save_dir=CLEAN_DATA_DIR)\n",
    "data_equal(comparee_dir=CLEAN_DATA_DIR, standard_dir=\"initial_data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
